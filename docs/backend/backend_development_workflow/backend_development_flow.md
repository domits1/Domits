## Why?
We want everyone to follow a set workflow. The reason for this, is that it has been impossible to manage version control for our backend development up to this point. With this workflow, our pipelines automatically test and deploy our code which means we always have version control in this repository and our code always matches the quality required by our tests.

## Backend directory structure
Our backend directory is split in 4 parts: CD, events, functions and test. Only senior developers and DevOps engineers are allowed to edit the CD directory. This directory is responsible for creating new backend functionalities and the original templates that these functionalities use. The events directory is where you write events to be handled by your functionality, this is mostly to run a full test of your functionality from start to finish. The functions directory is where you write your functionality which you want to deploy to aws. Finally the test directory is where you write tests for your functionality, we do this to ensure quality code. We always want to have full faith, that our code does what we expect it to do, we achieve this by writing unit-, integration- and end-to-end-tests as well as implementing monkey- and property-based-testing.

## Backend functionality architecture
Each backend functionality is originally made up of a layered architecture. These layers are the: controller-, business- and data-layer. Each layer has its own responsibility. There are also a couple of simple rules regarding which layer is allowed to communicate with which: the controller may only communicate with the business layer, the business layer can only respond to the controller layer but fully communicate with the data layer, and the data layer may only give responses to the business layer.

### Controller
The controller has to receive the request from your index.js file (this is where you route requests to the correct methods) and parse the contents you need from it (think of a POST request where you have to parse the request body). We also perform our authorization here, in most backend frameworks, you write middleware functions which you can implement in the routing of a method. But because we use plain javascript, this is not as simple. For this reason, we call our authorization methods from the top level of our controller method. After parsing and authorizing the request, the controller method should give the needed data (for this method) to the business layer.

### Business
In your business layer, you validate request data. You can do this by creating a model of the entity that you are working with and adding validation to this model. Think of a property having a type like villa or boat, these types are set in our database so before creating a property, we have to validate that the property type given in the request, actually exists in our database to prevent inconsistency. If you have a method that makes multiple calls to a data layer, then this will also be the place for you to confirm certain data with your own data (Think of retrieving a property which first requires an id, to fetch data from different tables in our database. You will first need to confirm that the property actually exists so you call the main property table. If the property does exist, you can return the id of the property and use this id to fetch data from different tables of the property entity).

### Data
In your data layer, you only communicate with data sources. This could be a different api, a database or an outside source. When you retrieve data, you always map the response to a readable object using a mapping function (more on these in the util section) and return it to the business layer.

### Util
In your functionality, you might need some utility functions that don't really fit in your business- or data-layers. For this we have a util directory, in this directory, you can write mapping functions which rewrite data to readable objects. In AWS for example, most data sources return values like this: { "id": { "S": "123456789" } }. This is not as readable and easy to work with, so we write a mapping function that rewrites it to: { "id": "123456789" }. Other things like custom exceptions, HTTP headers and extra parsing methods would also fit in this directory but use your own discretion for what fits in this directory.

### Sequence
![image](https://github.com/user-attachments/assets/317301f2-9f58-4cfc-a0bc-ba1394d1b3d7)
Zie: [https://github.com/domits1/Domits/wiki/Backend-development-workflow-Sequence-Diagram](https://github.com/domits1/Domits/wiki/Backend-development-workflow-Sequence-Diagram)

## Setting up your backend development environment
To develop a backend functionality, there are a few things you must do first to get set up. The first is to install and setup the AWS CLI, next is to understand the architecture listed above and understand why it's important for each layer to have its own responsibility. And finally, you can use a script to create your functionality.

### Install AWS CLI
First install the AWS CLI by following the instructions for your OS, listed here: [https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).

### Generate an access key
After installing the AWS CLI, we need to generate an AWS Access Key. To get your AWS Access Key, open the aws console in your browser and search for the IAM service. In IAM, navigate too 'Users' under 'Access Management'. In 'Users', lookup your own IAM user profile and open it. In your IAM user profile, you should see a 'Create access key' link under Access Key 1. Click this and select Command Line Interface (CLI) and click the checkbox at the bottom of the screen, then click 'Next'. Next write a description tag like: "AWS CLI Home PC" and then click 'Create access key'. On the next screen, click the 'Download .csv file' and click 'Done'.

### Configuring AWS CLI
After you get your access key, open a Command Prompt by pressing `windows key + r` and typing `cmd`. In your Command Prompt, run `aws configure`. You will be asked for an 'AWS Access Key ID'. Open the .csv file you downloaded in the last step and copy + paste, the access key id into your Command Prompt (note that the id and actual key are usually on a single line only seperated by a comma). After entering your access key id, you will be asked to enter your secret access key. Once again, open the .csv file you downloaded in the last step and copy + paste, the secret access key into your Command Prompt (Once again, note that the id and actual key are usually on a single line only seperated by a comma). After entering your secret access key, you will be asked for your default region name, here you must enter: "eu-north-1". Finally you will be asked for a default output format, set this to "json".

## Creating your backend functionality
To create your backend functionality, you first need a plan. Try to workout a sequence of how the flow of your functionality will look (similair to the sequence diagram above). When you have your plan, go into your IDE and open the backend directory of the Domits repository. Open a terminal and type: `npm run createLambda`. This will run a script that allows you to select a name for your function afterwhich it will create and connect your API and Lambda function. If you already have a backend functionality worked out in API Gateway and Lambda and only want to create the folder setup, run `npm run createLambda false`. This will register your functionality for future deployments but won't create a new API and Lambda function (note, if you don't want to create a new API and Lambda fucntion, make sure that you enter the exact name of your already existing function when asked for it as this is used to deploy your functionalities). You will receive a message that all steps were completed successfully once everything is correctly setup, please don't make any changes before seeing this success message.

## Notes
When installing new dependencies, install them in the root package.json in the backend/ directory. Also, only install the dependencies in this directory, running npm install in a different directory can mess with the build when deploying to aws.
When you want to test your event, create a get.js/post.js etc. file in the backend/events directory (in the directory of your own function). In this file, make a function that calls your handler function in the backend/functions directory and at the bottom of the file add a function invocation. Finally to run your event, type the following command in your terminal `node events/sometestfunction/get.js`, this will run your event, (add a console.log() to check what your function returns).

## Deploying
To deploy your functionality, start with committing and pushing your changes to your own branch. Next make a pull request to the acceptance branch, this will start a pipeline which will test all code, if the pipeline fails, open the pipeline and check what went wrong, fix the issue and commit the new changes. When the pipeline succeeds, someone will be allowed to review your code and give you feedback when needed. When all feedback has been implemented, merge your pull request to the acceptance branch and the deployment pipeline will automatically deploy your changed functionalities to AWS. If the pipeline fails, you will have to revert your merge and fix whatever caused the pipeline to fail.